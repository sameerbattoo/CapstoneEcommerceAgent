# ECommerce Agent - Monitoring & Observability Guide

## Overview

This document describes the comprehensive monitoring and observability strategy for the ECommerce Agent solution, including metrics, logs, traces, and dashboards.

---

## Observability Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Application Layer                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ Orchestrator │  │  SQL Agent   │  │   KB Agent   │     │
│  │    Agent     │  │              │  │              │     │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘     │
│         │                  │                  │              │
│         └──────────────────┼──────────────────┘              │
│                            │                                 │
└────────────────────────────┼─────────────────────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                  Metrics Logger Module                       │
│              (metrics_logger.py)                            │
└────────────────────────────┬─────────────────────────────────┘
                             │
        ┌────────────────────┼────────────────────┐
        │                    │                    │
        ▼                    ▼                    ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│  CloudWatch  │    │  CloudWatch  │    │  CloudWatch  │
│   Metrics    │    │     Logs     │    │   Insights   │
└──────────────┘    └──────────────┘    └──────────────┘
        │                    │                    │
        └────────────────────┼────────────────────┘
                             │
                             ▼
                    ┌──────────────┐
                    │  CloudWatch  │
                    │  Dashboards  │
                    └──────────────┘
```

---

## 1. CloudWatch Metrics

### Metrics Namespace
```
CapstoneECommerceAgent/PerTenant
```

### Metric Dimensions

#### Primary Dimensions
- **TenantId**: Tenant identifier (e.g., "tenanta", "tenantb")
- **SessionId**: Unique session identifier
- **StepName**: Agent or operation name

#### Secondary Dimensions
- **Region**: AWS region (e.g., "us-west-2")
- **Environment**: Deployment environment (e.g., "prod", "dev")

### Core Metrics

#### 1. Latency Metrics

**Metric Name**: `Latency`  
**Unit**: Milliseconds  
**Description**: Time taken to complete an operation

**Dimensions**:
```python
{
    'TenantId': 'tenanta',
    'StepName': 'orchestration_agent_execution'
}
```

**Step Names**:
- `orchestration_agent_execution`: Orchestrator agent processing
- `sql_agent_execution`: SQL agent query processing
- `kb_agent_execution`: Knowledge Base agent retrieval
- `chart_agent_execution`: Chart generation
- `mcp_tool_product_reviews`: Reviews API call
- `capstone_ecommerce_E2E_agent_execution`: End-to-end request

**Example**:
```python
cloudwatch.put_metric_data(
    Namespace='CapstoneECommerceAgent/PerTenant',
    MetricData=[{
        'MetricName': 'Latency',
        'Value': 2450.5,
        'Unit': 'Milliseconds',
        'Dimensions': [
            {'Name': 'TenantId', 'Value': 'tenanta'},
            {'Name': 'StepName', 'Value': 'sql_agent_execution'}
        ],
        'Timestamp': datetime.utcnow()
    }]
)
```

#### 2. Token Metrics

**Metric Names**:
- `InputTokens`: Tokens sent to model
- `OutputTokens`: Tokens generated by model
- `CacheReadTokens`: Tokens read from prompt cache
- `CacheWriteTokens`: Tokens written to prompt cache

**Unit**: Count

**Example**:
```python
cloudwatch.put_metric_data(
    Namespace='CapstoneECommerceAgent/PerTenant',
    MetricData=[
        {
            'MetricName': 'InputTokens',
            'Value': 1250,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': 'tenanta'},
                {'Name': 'StepName', 'Value': 'orchestration_agent_execution'}
            ]
        },
        {
            'MetricName': 'OutputTokens',
            'Value': 450,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': 'tenanta'},
                {'Name': 'StepName', 'Value': 'orchestration_agent_execution'}
            ]
        },
        {
            'MetricName': 'CacheReadTokens',
            'Value': 3500,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': 'tenanta'},
                {'Name': 'StepName', 'Value': 'orchestration_agent_execution'}
            ]
        }
    ]
)
```

#### 3. Cost Metrics

**Metric Name**: `Cost`  
**Unit**: None (USD)  
**Description**: Estimated cost for the operation

**Calculation**:
```python
def calculate_cost(
    input_tokens: int,
    output_tokens: int,
    model_id: str,
    cache_read_tokens: int = 0,
    cache_write_tokens: int = 0
) -> Dict[str, float]:
    """Calculate cost based on token usage."""
    
    # Model pricing (per 1M tokens)
    pricing = {
        'anthropic.claude-3-5-sonnet-20241022-v2:0': {
            'input': 0.003,
            'output': 0.015,
            'cache_read': 0.0003,
            'cache_write': 0.00375
        },
        'anthropic.claude-haiku-4-5-20251001-v1:0': {
            'input': 0.0008,
            'output': 0.004,
            'cache_read': 0.00008,
            'cache_write': 0.001
        }
    }
    
    model_pricing = pricing.get(model_id, pricing['anthropic.claude-3-5-sonnet-20241022-v2:0'])
    
    # Calculate costs
    input_cost = (input_tokens / 1000) * model_pricing['input']
    output_cost = (output_tokens / 1000) * model_pricing['output']
    cache_read_cost = (cache_read_tokens / 1000) * model_pricing['cache_read']
    cache_write_cost = (cache_write_tokens / 1000) * model_pricing['cache_write']
    
    total_cost = input_cost + output_cost + cache_read_cost + cache_write_cost
    
    # Calculate savings from caching
    cache_savings = (cache_read_tokens / 1000) * (model_pricing['input'] - model_pricing['cache_read'])
    
    return {
        'input_cost_usd': input_cost,
        'output_cost_usd': output_cost,
        'cache_read_cost_usd': cache_read_cost,
        'cache_write_cost_usd': cache_write_cost,
        'total_cost_usd': total_cost,
        'cache_savings_usd': cache_savings
    }
```

#### 4. Cache Metrics

**Metric Names**:
- `SemanticCacheHit`: Semantic cache hit occurred
- `SemanticCacheMiss`: Semantic cache miss occurred
- `PromptCacheHit`: Prompt cache hit occurred

**Unit**: Count

**Example**:
```python
cloudwatch.put_metric_data(
    Namespace='CapstoneECommerceAgent/PerTenant',
    MetricData=[{
        'MetricName': 'SemanticCacheHit',
        'Value': 1,
        'Unit': 'Count',
        'Dimensions': [
            {'Name': 'TenantId', 'Value': 'tenanta'},
            {'Name': 'StepName', 'Value': 'sql_agent_execution'}
        ]
    }]
)
```

#### 5. Error Metrics

**Metric Names**:
- `ErrorCount`: Number of errors
- `ErrorRate`: Percentage of requests with errors

**Unit**: Count / Percent

**Example**:
```python
cloudwatch.put_metric_data(
    Namespace='CapstoneECommerceAgent/PerTenant',
    MetricData=[{
        'MetricName': 'ErrorCount',
        'Value': 1,
        'Unit': 'Count',
        'Dimensions': [
            {'Name': 'TenantId', 'Value': 'tenanta'},
            {'Name': 'StepName', 'Value': 'sql_agent_execution'},
            {'Name': 'ErrorType', 'Value': 'DatabaseConnectionError'}
        ]
    }]
)
```

### Metrics Logger Implementation

**File**: `metrics_logger.py`

```python
import boto3
import logging
from datetime import datetime
from typing import Dict, Any, Optional

# Global CloudWatch client
cloudwatch_client = None
metrics_namespace = None
metrics_enabled = True

def initialize_metrics_logging(
    namespace: str = "CapstoneECommerceAgent/PerTenant",
    enable_metrics: bool = True
):
    """Initialize metrics logging."""
    global cloudwatch_client, metrics_namespace, metrics_enabled
    
    metrics_namespace = namespace
    metrics_enabled = enable_metrics
    
    if metrics_enabled:
        cloudwatch_client = boto3.client('cloudwatch')

def emit_step_metrics(
    logger: logging.Logger,
    session_id: str,
    tenant_id: str,
    step_name: str,
    start_time: float,
    end_time: float,
    input_tokens: int,
    output_tokens: int,
    cache_read_tokens: int = 0,
    cache_write_tokens: int = 0,
    status: str = "success",
    additional_data: Optional[Dict[str, Any]] = None
):
    """Emit step-level metrics to CloudWatch."""
    
    if not metrics_enabled or not cloudwatch_client:
        return
    
    duration_ms = (end_time - start_time) * 1000
    
    # Calculate cost
    cost_breakdown = calculate_cost(
        input_tokens,
        output_tokens,
        "anthropic.claude-3-5-sonnet-20241022-v2:0",
        cache_read_tokens,
        cache_write_tokens
    )
    
    # Prepare metric data
    metric_data = [
        {
            'MetricName': 'Latency',
            'Value': duration_ms,
            'Unit': 'Milliseconds',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name},
                {'Name': 'Status', 'Value': status}
            ],
            'Timestamp': datetime.utcnow()
        },
        {
            'MetricName': 'InputTokens',
            'Value': input_tokens,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name}
            ],
            'Timestamp': datetime.utcnow()
        },
        {
            'MetricName': 'OutputTokens',
            'Value': output_tokens,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name}
            ],
            'Timestamp': datetime.utcnow()
        },
        {
            'MetricName': 'Cost',
            'Value': cost_breakdown['total_cost_usd'],
            'Unit': 'None',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name}
            ],
            'Timestamp': datetime.utcnow()
        }
    ]
    
    # Add cache metrics if present
    if cache_read_tokens > 0:
        metric_data.append({
            'MetricName': 'CacheReadTokens',
            'Value': cache_read_tokens,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name}
            ],
            'Timestamp': datetime.utcnow()
        })
    
    if cache_write_tokens > 0:
        metric_data.append({
            'MetricName': 'CacheWriteTokens',
            'Value': cache_write_tokens,
            'Unit': 'Count',
            'Dimensions': [
                {'Name': 'TenantId', 'Value': tenant_id},
                {'Name': 'StepName', 'Value': step_name}
            ],
            'Timestamp': datetime.utcnow()
        })
    
    # Emit metrics
    try:
        cloudwatch_client.put_metric_data(
            Namespace=metrics_namespace,
            MetricData=metric_data
        )
        
        logger.debug(
            f"Emitted metrics for {step_name}: "
            f"latency={duration_ms:.2f}ms, "
            f"tokens={input_tokens}/{output_tokens}, "
            f"cost=${cost_breakdown['total_cost_usd']:.6f}"
        )
    
    except Exception as e:
        logger.error(f"Failed to emit metrics: {str(e)}")
```

---

## 2. CloudWatch Logs

### Log Groups

#### AgentCore Runtime Logs
```
/aws/bedrock/agentcore/runtime/capstone_ecomm_agent-iOd15C2EqB
```

**Log Events**:
- Agent initialization
- Request processing
- Tool invocations
- Error traces
- Performance metrics

#### Lambda Function Logs
```
/aws/lambda/ProductReviewsAPI
```

**Log Events**:
- Function invocations
- DynamoDB queries
- Tenant ID extraction
- Error traces

### Log Format

**Structured Logging**:
```python
import logging
import json

logger = logging.getLogger("eCommerceAgent")
logger.setLevel(logging.INFO)

# Structured log entry
logger.info(json.dumps({
    'timestamp': '2024-12-26T15:30:45Z',
    'level': 'INFO',
    'session_id': 'session-abc123',
    'tenant_id': 'tenanta',
    'user_email': 'john.doe@email.com',
    'step': 'sql_agent_execution',
    'message': 'SQL query executed successfully',
    'duration_ms': 245.5,
    'input_tokens': 1000,
    'output_tokens': 300,
    'cache_hit': True
}))
```

### Log Levels

- **ERROR**: Errors requiring immediate attention
- **WARNING**: Potential issues or degraded performance
- **INFO**: Normal operational events
- **DEBUG**: Detailed diagnostic information

**Configuration**:
```python
LOG_LEVEL = os.getenv("LOG_LEVEL", "WARNING")
logging.basicConfig(level=getattr(logging, LOG_LEVEL))
```

### Log Insights Queries

#### Query 1: Average Latency by Tenant
```sql
fields @timestamp, tenant_id, duration_ms
| filter step = "capstone_ecommerce_E2E_agent_execution"
| stats avg(duration_ms) as avg_latency by tenant_id
| sort avg_latency desc
```

#### Query 2: Error Rate by Step
```sql
fields @timestamp, step, level
| filter level = "ERROR"
| stats count() as error_count by step
| sort error_count desc
```

#### Query 3: Cache Hit Rate
```sql
fields @timestamp, cache_hit
| filter step = "sql_agent_execution"
| stats count() as total, sum(cache_hit) as hits
| fields hits / total * 100 as cache_hit_rate
```

#### Query 4: Token Usage by Tenant
```sql
fields @timestamp, tenant_id, input_tokens, output_tokens
| stats sum(input_tokens) as total_input, sum(output_tokens) as total_output by tenant_id
| fields tenant_id, total_input, total_output, total_input + total_output as total_tokens
| sort total_tokens desc
```

#### Query 5: Top Expensive Queries
```sql
fields @timestamp, session_id, tenant_id, cost_usd
| filter step = "capstone_ecommerce_E2E_agent_execution"
| sort cost_usd desc
| limit 20
```

---

## 3. CloudWatch Dashboards

### Dashboard: ECommerce Agent Overview

**Widgets**:

#### 1. End-to-End Latency (Line Chart)
```json
{
  "metrics": [
    ["CapstoneECommerceAgent/PerTenant", "Latency", {"stat": "Average", "label": "Avg Latency"}],
    ["...", {"stat": "p50", "label": "P50"}],
    ["...", {"stat": "p90", "label": "P90"}],
    ["...", {"stat": "p99", "label": "P99"}]
  ],
  "period": 300,
  "stat": "Average",
  "region": "us-west-2",
  "title": "End-to-End Latency",
  "yAxis": {
    "left": {
      "label": "Milliseconds"
    }
  }
}
```

#### 2. Token Usage (Stacked Area Chart)
```json
{
  "metrics": [
    ["CapstoneECommerceAgent/PerTenant", "InputTokens", {"stat": "Sum"}],
    [".", "OutputTokens", {"stat": "Sum"}],
    [".", "CacheReadTokens", {"stat": "Sum"}]
  ],
  "period": 300,
  "stat": "Sum",
  "region": "us-west-2",
  "title": "Token Usage Over Time",
  "yAxis": {
    "left": {
      "label": "Tokens"
    }
  }
}
```

#### 3. Cost by Tenant (Bar Chart)
```json
{
  "metrics": [
    ["CapstoneECommerceAgent/PerTenant", "Cost", {"stat": "Sum", "dimensions": {"TenantId": "tenanta"}}],
    ["...", {"dimensions": {"TenantId": "tenantb"}}]
  ],
  "period": 3600,
  "stat": "Sum",
  "region": "us-west-2",
  "title": "Cost by Tenant (Hourly)"
}
```

#### 4. Cache Hit Rate (Number Widget)
```json
{
  "metrics": [
    ["CapstoneECommerceAgent/PerTenant", "SemanticCacheHit", {"stat": "Sum", "id": "hits"}],
    [".", "SemanticCacheMiss", {"stat": "Sum", "id": "misses"}]
  ],
  "period": 3600,
  "stat": "Sum",
  "region": "us-west-2",
  "title": "Cache Hit Rate",
  "expression": "hits / (hits + misses) * 100"
}
```

#### 5. Error Rate (Line Chart)
```json
{
  "metrics": [
    ["CapstoneECommerceAgent/PerTenant", "ErrorCount", {"stat": "Sum"}]
  ],
  "period": 300,
  "stat": "Sum",
  "region": "us-west-2",
  "title": "Error Count",
  "yAxis": {
    "left": {
      "label": "Errors"
    }
  }
}
```

### Dashboard: Per-Tenant Performance

**Widgets**:
- Latency by tenant (multi-line chart)
- Token usage by tenant (stacked bar chart)
- Cost by tenant (pie chart)
- Request count by tenant (number widgets)

### Dashboard: Agent Performance Breakdown

**Widgets**:
- Latency by step (stacked bar chart)
- Token usage by agent (table)
- Cache performance by agent (bar chart)
- Error rate by agent (line chart)

---

## 4. Alarms

### Critical Alarms

#### 1. High Latency Alarm
```json
{
  "AlarmName": "ECommerceAgent-HighLatency",
  "MetricName": "Latency",
  "Namespace": "CapstoneECommerceAgent/PerTenant",
  "Statistic": "Average",
  "Period": 300,
  "EvaluationPeriods": 2,
  "Threshold": 8000,
  "ComparisonOperator": "GreaterThanThreshold",
  "AlarmDescription": "Average latency exceeds 8 seconds",
  "AlarmActions": ["arn:aws:sns:us-west-2:123456789012:ops-alerts"]
}
```

#### 2. High Error Rate Alarm
```json
{
  "AlarmName": "ECommerceAgent-HighErrorRate",
  "MetricName": "ErrorCount",
  "Namespace": "CapstoneECommerceAgent/PerTenant",
  "Statistic": "Sum",
  "Period": 300,
  "EvaluationPeriods": 2,
  "Threshold": 10,
  "ComparisonOperator": "GreaterThanThreshold",
  "AlarmDescription": "Error count exceeds 10 in 5 minutes",
  "AlarmActions": ["arn:aws:sns:us-west-2:123456789012:ops-alerts"]
}
```

#### 3. Low Cache Hit Rate Alarm
```json
{
  "AlarmName": "ECommerceAgent-LowCacheHitRate",
  "Metrics": [
    {"Id": "hits", "MetricStat": {"Metric": {"Namespace": "CapstoneECommerceAgent/PerTenant", "MetricName": "SemanticCacheHit"}, "Period": 3600, "Stat": "Sum"}},
    {"Id": "misses", "MetricStat": {"Metric": {"Namespace": "CapstoneECommerceAgent/PerTenant", "MetricName": "SemanticCacheMiss"}, "Period": 3600, "Stat": "Sum"}},
    {"Id": "rate", "Expression": "hits / (hits + misses) * 100"}
  ],
  "EvaluationPeriods": 2,
  "Threshold": 30,
  "ComparisonOperator": "LessThanThreshold",
  "AlarmDescription": "Cache hit rate below 30%",
  "AlarmActions": ["arn:aws:sns:us-west-2:123456789012:ops-alerts"]
}
```

---

## 5. Distributed Tracing

### X-Ray Integration

**Enable X-Ray**:
```python
from aws_xray_sdk.core import xray_recorder
from aws_xray_sdk.ext.flask.middleware import XRayMiddleware

# Initialize X-Ray
xray_recorder.configure(service='ECommerceAgent')

# Trace function
@xray_recorder.capture('process_query')
def process_query(query: str):
    # Add metadata
    xray_recorder.put_metadata('query', query)
    xray_recorder.put_annotation('tenant_id', tenant_id)
    
    # Process query
    result = agent.invoke(query)
    
    return result
```

**Trace Segments**:
- AgentCore invocation
- SQL Agent execution
- KB Agent retrieval
- Lambda function calls
- Database queries

---

## 6. Monitoring Best Practices

### 1. Set Baseline Metrics
- Establish normal operating ranges
- Define SLOs (Service Level Objectives)
- Set appropriate alarm thresholds

### 2. Monitor Key Metrics
- Latency (P50, P90, P99)
- Error rate
- Token usage and cost
- Cache hit rate

### 3. Use Structured Logging
- JSON format for easy parsing
- Include context (session_id, tenant_id)
- Log at appropriate levels

### 4. Create Actionable Alarms
- Avoid alarm fatigue
- Set meaningful thresholds
- Include runbook links

### 5. Regular Review
- Weekly performance reviews
- Monthly cost analysis
- Quarterly capacity planning

---

**Document Version**: 2.0  
**Last Updated**: January 2026  
**Author**: Sameer Battoo (sbattoo@amazon.com)
